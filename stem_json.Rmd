---
title: "stem_json"
author: "Lei Chen"
date: "2/15/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(magrittr)
library(dplyr)
library(stringr)
library(tibble)
```

## Introduction

## Human scores
```{r load_hs}
hs<-read_excel('hscore/CBAL_2015.xlsx')
# trick http://bit.ly/2lA0ZJp for dealing with duplicated colnames
hs2 <- hs %>%
    setNames(make.unique(names(.)))
names(hs2)
```

```{r tidy}
n_row = dim(hs2)[1]
new_cols<-c('ID', 'FileName', 'TimeSpent', 'Image', 'Text',
            'hs.scale', 'hs.material', 'hs.behavior', 'hs.distribution', 'hs.lp')

one_question <- function(idx, Q_token){
  cols = c(1, idx:(idx+8))
  
  part <- hs2 %>%
    select(cols) %>%
    set_colnames(new_cols) %>%
    add_column(Question = rep(Q_token, n_row))
  return(part)
}

q1<-one_question(3, 'Part1_Q1')
q2<-one_question(12, 'Part1_Q3')
q3<-one_question(21, 'Part1_Q4')
q4<-one_question(30, 'Part2_Q16')
q5<-one_question(39, 'Part3_Q10')
q6<-one_question(48, 'Part3_Q12')
q7<-one_question(57, 'Part4_Q5')
q8<-one_question(66, 'Part4_Q7')
q9<-one_question(75, 'Part5_Q1')
q10<-one_question(84, 'Part5_Q2')
q11<-one_question(93, 'Part5_Q3')

all_tb <- rbind(q1,q2,q3,q4,q5,q6,q7,q8,q9,q10,q11)
valid_tb <- all_tb %>%
  filter(!grepl("NP|B", hs.scale)) %>%
  filter(!is.na(hs.scale))

write_csv(valid_tb, 'hscore/hs_tidy.csv')

```


```{r comb_feat_score, results="asis"}
# compute num of words from Text
valid_tb <- valid_tb %>%
  mutate(wds=str_count(Text, "\\S+"))

#library(ggplot2)
#ggplot(valid_tb, aes(hs.scale, wds)) +
#  geom_line(aes(group = Question)) +
#  geom_point(aes(colour = Question))
```

Loading counting features and conduct correlation analysis
```{r counting_features}
cnt_feats <- read.csv('features/counting_features.csv')
# names(cnt_feats)

# 580230-CMS60000702-S_OCEANWATER_SP13_01_03_M
id_2_fname <- function(id_str){
  id_rept <- "\\d+-(\\w+)-S_OCEANWATER_SP13_0?(\\d+)_0?(\\d+)"
  tks <- str_match(id_str, id_rept)
  fname <- paste(tks[2], tks[3], tks[4], sep='_')
  fname
  
}

# id_str <- "580230-CMS60000702-S_OCEANWATER_SP13_01_03_M"
# foo <- id_2_fname(id_str)
# foo

cnt_feats <- cnt_feats %>%
  mutate(FileName=lapply(id, id_2_fname))

feats_score <- merge(cnt_feats, valid_tb, by="FileName", sort = F)

chr2num <- function(chr){
  return(as.numeric(as.factor(chr)))
}

feats_score[11:15] <- lapply(feats_score[11:15], chr2num)
corr_tb <- cor(feats_score[3:6], feats_score[11:15], use="complete.obs")
corr_tb

```

```{r ggplot2}
ggplot(feats_score, aes(x=hs.behavior, y=log(num_arrows + 1)         )) +
    geom_point(shape=1) +    # Use hollow circles
    geom_smooth(method=lm)   # Add a loess smoothed fit curve with confidence region
```

Fore each human score, check four counting features' correlation patterns.
```{r each_score}
# wide to long for plot multiple lines
long_tb <- feats_score %>%
  gather(`micro_obj_types`, `micro_obj_color_types`, `macro_obj_types`, `num_arrows`, key='feature', value='value')

ggplot(long_tb, aes(x=hs.scale, y=log(value+1), group=feature, colour=feature)) +
    geom_point(shape=1) +    # Use hollow circles
    geom_smooth(method=lm)   # 

ggplot(long_tb, aes(x=hs.material, y=log(value+1), group=feature, colour=feature)) +
    geom_point(shape=1) +    # Use hollow circles
    geom_smooth(method=lm)   # 

ggplot(long_tb, aes(x=hs.behavior, y=log(value+1), group=feature, colour=feature)) +
    geom_point(shape=1) +    # Use hollow circles
    geom_smooth(method=lm)   # 

ggplot(long_tb, aes(x=hs.distribution, y=log(value+1), group=feature, colour=feature)) +
    geom_point(shape=1) +    # Use hollow circles
    geom_smooth(method=lm)   # 

ggplot(long_tb, aes(x=hs.lp, y=log(value+1), group=feature, colour=feature)) +
    geom_point(shape=1) +    # Use hollow circles
    geom_smooth(method=lm)   # 
```

